{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bigcon1 분석 노트북\n",
        "\n",
        "이 노트북은 `bigcon1.py` 스크립트를 단락별로 분리하여 실행 가능한 형태로 구성했습니다. 각 섹션은 원본 스크립트의 흐름을 유지합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 데이터 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ENCODED_MCT  MCT_BSE_AR MCT_NM MCT_BRD_NUM MCT_SIGUNGU_NM HPSN_MCT_ZCD_NM  \\\n",
            "0  16184E93D9  서울 성동구 마장동   성우**         NaN         서울 성동구             축산물   \n",
            "1  4D039EA8B7  서울 성동구 마장동   대보**         NaN         서울 성동구             축산물   \n",
            "2  0074C4990A  서울 성동구 마장동   대용**         NaN         서울 성동구             축산물   \n",
            "3  68308F2746  서울 성동구 마장동   통일**         NaN         서울 성동구             축산물   \n",
            "4  4117EDDE9C  서울 성동구 마장동   한울**         NaN         서울 성동구             축산물   \n",
            "\n",
            "  HPSN_MCT_BZN_CD_NM     ARE_D  MCT_ME_D  \n",
            "0                마장동  20130320       NaN  \n",
            "1                마장동  20131122       NaN  \n",
            "2                마장동  20140512       NaN  \n",
            "3                마장동  20151124       NaN  \n",
            "4                마장동  20151211       NaN  \n",
            "  ENCODED_MCT   TA_YM MCT_OPE_MS_CN           RC_M1_SAA      RC_M1_TO_UE_CT  \\\n",
            "0  000F03E44A  202404      4_50-75%            5_75-90%            5_75-90%   \n",
            "1  000F03E44A  202312      4_50-75%  6_90%초과(하위 10% 이하)  6_90%초과(하위 10% 이하)   \n",
            "2  002816BA73  202404      2_10-25%            3_25-50%            4_50-75%   \n",
            "3  002816BA73  202411      2_10-25%            3_25-50%            4_50-75%   \n",
            "4  002816BA73  202406      2_10-25%            4_50-75%            4_50-75%   \n",
            "\n",
            "      RC_M1_UE_CUS_CN      RC_M1_AV_NP_AT      APV_CE_RAT  DLV_SAA_RAT  \\\n",
            "0            5_75-90%            5_75-90%         1_상위1구간    -999999.9   \n",
            "1  6_90%초과(하위 10% 이하)  6_90%초과(하위 10% 이하)             NaN    -999999.9   \n",
            "2            4_50-75%            2_10-25%  6_상위6구간(하위1구간)    -999999.9   \n",
            "3            4_50-75%            2_10-25%  6_상위6구간(하위1구간)    -999999.9   \n",
            "4            4_50-75%            2_10-25%         1_상위1구간    -999999.9   \n",
            "\n",
            "   M1_SME_RY_SAA_RAT  M1_SME_RY_CNT_RAT  M12_SME_RY_SAA_PCE_RT  \\\n",
            "0                2.6               10.6                   93.8   \n",
            "1                0.0                0.0                   94.8   \n",
            "2               96.6               40.8                   15.6   \n",
            "3              108.0               46.4                   16.8   \n",
            "4               74.2               38.1                   16.0   \n",
            "\n",
            "   M12_SME_BZN_SAA_PCE_RT  M12_SME_RY_ME_MCT_RAT  M12_SME_BZN_ME_MCT_RAT  \n",
            "0                    71.5                   16.7                     7.8  \n",
            "1                    73.4                   16.6                     7.2  \n",
            "2                    20.0                   17.5                     5.2  \n",
            "3                    19.8                   16.9                     6.9  \n",
            "4                    19.9                   17.3                     5.6  \n",
            "  ENCODED_MCT   TA_YM  M12_MAL_1020_RAT  M12_MAL_30_RAT  M12_MAL_40_RAT  \\\n",
            "0  0305234DDB  202311               0.0             0.0           100.0   \n",
            "1  0495B069FF  202403               0.0             0.0           100.0   \n",
            "2  0495B069FF  202405               0.0             0.0           100.0   \n",
            "3  0495B069FF  202406               0.0             0.0           100.0   \n",
            "4  055EDDDD01  202410               0.0             0.0             0.0   \n",
            "\n",
            "   M12_MAL_50_RAT  M12_MAL_60_RAT  M12_FME_1020_RAT  M12_FME_30_RAT  \\\n",
            "0             0.0             0.0               0.0             0.0   \n",
            "1             0.0             0.0               0.0             0.0   \n",
            "2             0.0             0.0               0.0             0.0   \n",
            "3             0.0             0.0               0.0             0.0   \n",
            "4             0.0             0.0               0.0             0.0   \n",
            "\n",
            "   M12_FME_40_RAT  M12_FME_50_RAT  M12_FME_60_RAT  MCT_UE_CLN_REU_RAT  \\\n",
            "0             0.0             0.0             0.0              100.00   \n",
            "1             0.0             0.0             0.0               25.00   \n",
            "2             0.0             0.0             0.0               33.33   \n",
            "3             0.0             0.0             0.0               33.33   \n",
            "4             0.0           100.0             0.0               33.33   \n",
            "\n",
            "   MCT_UE_CLN_NEW_RAT  RC_M1_SHC_RSD_UE_CLN_RAT  RC_M1_SHC_WP_UE_CLN_RAT  \\\n",
            "0                 0.0                 -999999.9                -999999.9   \n",
            "1                25.0                       0.0                      0.0   \n",
            "2                 0.0                 -999999.9                -999999.9   \n",
            "3                 0.0                 -999999.9                -999999.9   \n",
            "4                 0.0                 -999999.9                -999999.9   \n",
            "\n",
            "   RC_M1_SHC_FLP_UE_CLN_RAT  \n",
            "0                 -999999.9  \n",
            "1                     100.0  \n",
            "2                 -999999.9  \n",
            "3                 -999999.9  \n",
            "4                 -999999.9  \n"
          ]
        }
      ],
      "source": [
        "file_path = '/Users/yugeonhui/Downloads/big_data_set1_f.csv'\n",
        "\n",
        "df1 = pd.read_csv(file_path, encoding='cp949')\n",
        "\n",
        "file_path = '/Users/yugeonhui/Downloads/big_data_set2_f.csv'\n",
        "\n",
        "df2 = pd.read_csv(file_path, encoding='cp949')\n",
        "\n",
        "file_path = '/Users/yugeonhui/Downloads/big_data_set3_f.csv'\n",
        "\n",
        "df3 = pd.read_csv(file_path, encoding='cp949')\n",
        "\n",
        "print(df1.head())\n",
        "print(df2.head())\n",
        "print(df3.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "현재 작업 디렉토리: /Users/yugeonhui/Desktop/bigcontest\n",
            "DATA_DIR: .\n",
            "DATA_DIR 파일 목록:\n"
          ]
        }
      ],
      "source": [
        "# 진단: 작업 디렉토리와 파일 목록 확인\n",
        "import os\n",
        "print(\"현재 작업 디렉토리:\", os.getcwd())\n",
        "print(\"DATA_DIR:\", os.getenv('BIGCON_DATA_DIR', '.'))\n",
        "print(\"DATA_DIR 파일 목록:\")\n",
        "for name in os.listdir(os.getenv('BIGCON_DATA_DIR', '.')):\n",
        "    if name.lower().endswith('.csv'):\n",
        "        print(\" -\", name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 데이터 정제 및 Target 변수 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 데이터 정제 및 Target 변수 생성 시작 ===\n",
            "\n",
            "1. 특수값 처리 중...\n",
            "df2, df3의 -999999.9 값을 np.nan으로 변환 완료\n",
            "\n",
            "2. 날짜 컬럼 타입 변경 중...\n",
            "df1의 'ARE_D', 'MCT_ME_D' 컬럼을 datetime으로 변환 완료\n",
            "df2, df3의 'TA_YM' 컬럼을 datetime으로 변환 완료\n",
            "\n",
            "3. Target 변수 'is_closed' 생성 중...\n",
            "Target 변수 'is_closed' 생성 완료\n",
            "\n",
            "=== Target 변수 분포 확인 ===\n",
            "폐업/정상 가맹점 분포:\n",
            "is_closed\n",
            "0    4058\n",
            "1     127\n",
            "Name: count, dtype: int64\n",
            "\n",
            "분포 비율:\n",
            "is_closed\n",
            "0    0.969654\n",
            "1    0.030346\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "=== 데이터 정제 및 Target 변수 생성 완료 ===\n"
          ]
        }
      ],
      "source": [
        "# 데이터 정제 및 Target 변수 생성\n",
        "print(\"\\n=== 데이터 정제 및 Target 변수 생성 시작 ===\")\n",
        "\n",
        "# 1. 데이터 정제\n",
        "print(\"\\n1. 특수값 처리 중...\")\n",
        "# df2와 df3에서 -999999.9 값을 np.nan으로 변환\n",
        "df2 = df2.replace(-999999.9, np.nan)\n",
        "df3 = df3.replace(-999999.9, np.nan)\n",
        "print(\"df2, df3의 -999999.9 값을 np.nan으로 변환 완료\")\n",
        "\n",
        "# 2. 날짜 컬럼 타입 변경\n",
        "print(\"\\n2. 날짜 컬럼 타입 변경 중...\")\n",
        "# df1의 날짜 컬럼들\n",
        "df1['ARE_D'] = pd.to_datetime(df1['ARE_D'], format='%Y%m%d')\n",
        "df1['MCT_ME_D'] = pd.to_datetime(df1['MCT_ME_D'], format='%Y%m%d')\n",
        "print(\"df1의 'ARE_D', 'MCT_ME_D' 컬럼을 datetime으로 변환 완료\")\n",
        "\n",
        "# df2와 df3의 날짜 컬럼들\n",
        "df2['TA_YM'] = pd.to_datetime(df2['TA_YM'], format='%Y%m')\n",
        "df3['TA_YM'] = pd.to_datetime(df3['TA_YM'], format='%Y%m')\n",
        "print(\"df2, df3의 'TA_YM' 컬럼을 datetime으로 변환 완료\")\n",
        "\n",
        "# 3. Target 변수 생성\n",
        "print(\"\\n3. Target 변수 'is_closed' 생성 중...\")\n",
        "# MCT_ME_D에 날짜가 있으면(폐업) 1, 결측치면(정상 운영) 0\n",
        "df1['is_closed'] = df1['MCT_ME_D'].notna().astype(int)\n",
        "print(\"Target 변수 'is_closed' 생성 완료\")\n",
        "\n",
        "# 4. 결과 확인\n",
        "print(\"\\n=== Target 변수 분포 확인 ===\")\n",
        "print(\"폐업/정상 가맹점 분포:\")\n",
        "print(df1['is_closed'].value_counts())\n",
        "print(\"\\n분포 비율:\")\n",
        "print(df1['is_closed'].value_counts(normalize=True))\n",
        "\n",
        "print(\"\\n=== 데이터 정제 및 Target 변수 생성 완료 ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 데이터프레임 병합\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터프레임 병합\n",
        "print(\"\\n=== 데이터프레임 병합 시작 ===\")\n",
        "\n",
        "# 1단계: df2와 df3 병합 (월별 이용 정보 + 월별 고객 정보)\n",
        "print(\"\\n1단계: df2(월별 이용 정보)와 df3(월별 고객 정보) 병합 중...\")\n",
        "print(f\"df2 크기: {df2.shape}\")\n",
        "print(f\"df3 크기: {df3.shape}\")\n",
        "\n",
        "merged_df = pd.merge(df2, df3, on=['ENCODED_MCT', 'TA_YM'], how='inner')\n",
        "print(f\"1단계 병합 완료 - merged_df 크기: {merged_df.shape}\")\n",
        "\n",
        "# 2단계: merged_df와 df1 병합 (가맹점 개요 정보 추가)\n",
        "print(\"\\n2단계: merged_df와 df1(가맹점 개요 정보) 병합 중...\")\n",
        "print(f\"merged_df 크기: {merged_df.shape}\")\n",
        "print(f\"df1 크기: {df1.shape}\")\n",
        "\n",
        "final_df = pd.merge(merged_df, df1, on='ENCODED_MCT', how='left')\n",
        "print(f\"2단계 병합 완료 - final_df 크기: {final_df.shape}\")\n",
        "\n",
        "# 결과 확인\n",
        "print(\"\\n=== 최종 병합 결과 확인 ===\")\n",
        "print(f\"최종 데이터프레임 크기: {final_df.shape}\")\n",
        "print(f\"컬럼 수: {final_df.shape[1]}, 행 수: {final_df.shape[0]}\")\n",
        "\n",
        "print(\"\\n최종 데이터프레임 상위 5행:\")\n",
        "print(final_df.head())\n",
        "final_df.to_csv('final_df.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"final_df를 'final_df.csv' 파일로 저장 완료\")\n",
        "\n",
        "print(\"\\n=== 데이터프레임 병합 완료 ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 파생 변수(피처) 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 파생 변수(피처) 생성\n",
        "print(\"\\n=== 파생 변수 생성 시작 ===\")\n",
        "\n",
        "# 1. 운영 개월 수 계산\n",
        "print(\"\\n1. 운영 개월 수 계산 중...\")\n",
        "# TA_YM과 ARE_D의 차이를 월 단위로 계산\n",
        "final_df['operating_months'] = ((final_df['TA_YM'].dt.year - final_df['ARE_D'].dt.year) * 12 + \n",
        "                                (final_df['TA_YM'].dt.month - final_df['ARE_D'].dt.month))\n",
        "print(\"operating_months 컬럼 생성 완료\")\n",
        "\n",
        "# 2. 순위 컬럼 전처리\n",
        "print(\"\\n2. 순위 컬럼 전처리 중...\")\n",
        "\n",
        "# RC_M1_SAA에서 맨 앞 숫자만 추출하여 sales_rank_num 생성\n",
        "final_df['sales_rank_num'] = final_df['RC_M1_SAA'].str.extract(r'^(\\d+)').astype(int)\n",
        "print(\"sales_rank_num 컬럼 생성 완료\")\n",
        "\n",
        "# RC_M1_UE_CUS_CN에서 맨 앞 숫자만 추출하여 customer_rank_num 생성\n",
        "final_df['customer_rank_num'] = final_df['RC_M1_UE_CUS_CN'].str.extract(r'^(\\d+)').astype(int)\n",
        "print(\"customer_rank_num 컬럼 생성 완료\")\n",
        "\n",
        "# 3. 직전 월 대비 주요 지표 변화량 계산\n",
        "print(\"\\n3. 직전 월 대비 주요 지표 변화량 계산 중...\")\n",
        "\n",
        "# 각 가맹점별로 그룹화하여 직전 월 대비 차이 계산\n",
        "final_df = final_df.sort_values(['ENCODED_MCT', 'TA_YM'])\n",
        "\n",
        "# 숫자 랭크 컬럼을 사용하여 차이 계산\n",
        "final_df['sales_rank_diff'] = final_df.groupby('ENCODED_MCT')['sales_rank_num'].diff()\n",
        "final_df['customer_count_rank_diff'] = final_df.groupby('ENCODED_MCT')['customer_rank_num'].diff()\n",
        "print(\"sales_rank_diff, customer_count_rank_diff 컬럼 생성 완료\")\n",
        "\n",
        "# 4. 결과 확인\n",
        "print(\"\\n4. 결과 확인...\")\n",
        "print(\"\\n=== 순위 컬럼 전처리 및 차이 계산 결과 ===\")\n",
        "print(\"원본 컬럼과 새로 생성된 숫자 및 차이 컬럼 상위 10개 행:\")\n",
        "result_columns = ['RC_M1_SAA', 'sales_rank_num', 'sales_rank_diff']\n",
        "print(final_df[result_columns].head(10))\n",
        "\n",
        "print(\"\\n=== 추가 확인: 고객 수 순위 관련 컬럼 ===\")\n",
        "customer_columns = ['RC_M1_UE_CUS_CN', 'customer_rank_num', 'customer_count_rank_diff']\n",
        "print(final_df[customer_columns].head(10))\n",
        "\n",
        "print(\"\\n=== 순위 컬럼 전처리 및 차이 계산 완료 ===\")\n",
        "\n",
        "final_df.to_csv('final_df1.csv', index=False, encoding='utf-8-sig')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 모델링을 위한 최종 데이터 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델링을 위한 최종 데이터 준비\n",
        "print(\"\\n=== 모델링을 위한 최종 데이터 준비 시작 ===\")\n",
        "\n",
        "# 1. 피처(X)와 타겟(y) 정의\n",
        "print(\"\\n1. 피처(X)와 타겟(y) 정의 중...\")\n",
        "\n",
        "# 타겟 변수 정의\n",
        "y = final_df['is_closed']\n",
        "print(f\"타겟 변수 'y' 생성 완료 - shape: {y.shape}\")\n",
        "\n",
        "# 피처 변수 정의 (요청된 컬럼들)\n",
        "feature_columns = ['operating_months', 'sales_rank_num', 'customer_rank_num', \n",
        "                   'sales_rank_diff', 'customer_count_rank_diff', 'MCT_UE_CLN_REU_RAT']\n",
        "X = final_df[feature_columns]\n",
        "print(f\"피처 변수 'X' 생성 완료 - shape: {X.shape}\")\n",
        "print(f\"사용된 피처 컬럼: {feature_columns}\")\n",
        "\n",
        "# 2. 결측치(NaN) 처리\n",
        "print(\"\\n2. 결측치(NaN) 처리 중...\")\n",
        "print(\"처리 전 결측치 개수:\")\n",
        "print(X.isnull().sum())\n",
        "\n",
        "# 각 컬럼의 중앙값으로 결측치 채우기\n",
        "X = X.fillna(X.median())\n",
        "print(\"처리 후 결측치 개수:\")\n",
        "print(X.isnull().sum())\n",
        "print(\"결측치 처리 완료\")\n",
        "\n",
        "# 3. 학습용/테스트용 데이터 분리\n",
        "print(\"\\n3. 학습용/테스트용 데이터 분리 중...\")\n",
        "\n",
        "# scikit-learn의 train_test_split 임포트\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80:20 비율로 데이터 분리 (stratify 옵션으로 비율 유지)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=y\n",
        ")\n",
        "print(\"데이터 분리 완료\")\n",
        "\n",
        "# 4. 결과 확인\n",
        "print(\"\\n4. 결과 확인...\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train 분포:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(f\"y_test 분포:\")\n",
        "print(y_test.value_counts(normalize=True))\n",
        "\n",
        "print(\"\\n=== 모델링을 위한 최종 데이터 준비 완료 ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 베이스라인 모델: 로지스틱 회귀\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 베이스라인 모델 생성 및 평가\n",
        "print(\"\\n=== 베이스라인 모델 생성 및 평가 시작 ===\")\n",
        "\n",
        "# 1. 모델 학습\n",
        "print(\"\\n1. 로지스틱 회귀 모델 학습 중...\")\n",
        "\n",
        "# scikit-learn에서 LogisticRegression 임포트\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 로지스틱 회귀 모델 생성 및 학습\n",
        "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "print(\"로지스틱 회귀 모델 학습 완료\")\n",
        "\n",
        "# 2. 예측 수행\n",
        "print(\"\\n2. 테스트 데이터 예측 중...\")\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "print(\"예측 완료\")\n",
        "\n",
        "# 3. 모델 평가\n",
        "print(\"\\n3. 모델 평가 중...\")\n",
        "\n",
        "# scikit-learn의 metrics에서 필요한 함수들 임포트\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 정확도(Accuracy) 계산 및 출력\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n=== 모델 평가 결과 ===\")\n",
        "print(f\"정확도(Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "# 혼동 행렬(Confusion Matrix) 계산 및 출력\n",
        "print(f\"\\n혼동 행렬(Confusion Matrix):\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# 분류 리포트(Classification Report) 계산 및 출력\n",
        "print(f\"\\n분류 리포트(Classification Report):\")\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n",
        "\n",
        "# 4. 결과 해석 주석\n",
        "print(f\"\\n=== 결과 해석 ===\")\n",
        "print(\"\"\"\n",
        "혼동 행렬(Confusion Matrix) 해석:\n",
        "- [0,0]: 실제 정상(0)이고 예측도 정상(0)인 경우 (True Negative)\n",
        "- [0,1]: 실제 정상(0)이지만 예측은 폐업(1)인 경우 (False Positive) \n",
        "- [1,0]: 실제 폐업(1)이지만 예측은 정상(0)인 경우 (False Negative)\n",
        "- [1,1]: 실제 폐업(1)이고 예측도 폐업(1)인 경우 (True Positive)\n",
        "\n",
        "분류 리포트(Classification Report) 해석:\n",
        "- Precision (정밀도): 예측한 폐업 중 실제 폐업인 비율\n",
        "- Recall (재현율): 실제 폐업 중 올바르게 예측한 비율  \n",
        "- F1-score: 정밀도와 재현율의 조화평균\n",
        "- Support: 각 클래스의 실제 샘플 수\n",
        "- Macro avg: 각 클래스별 지표의 평균\n",
        "- Weighted avg: 각 클래스의 샘플 수에 따른 가중평균\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n=== 베이스라인 모델 생성 및 평가 완료 ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 가중치 조정 로지스틱 회귀 (class_weight='balanced')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class_weight='balanced'를 적용한 로지스틱 회귀 모델 재학습 및 평가\n",
        "print(\"\\n=== 가중치 조정(balanced) 로지스틱 회귀 재학습 및 평가 시작 ===\")\n",
        "\n",
        "# 1. 가중치 조정한 모델 생성 및 학습\n",
        "print(\"\\n1. balanced 로지스틱 회귀 모델 학습 중...\")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "balanced_model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
        "balanced_model.fit(X_train, y_train)\n",
        "print(\"balanced 로지스틱 회귀 모델 학습 완료\")\n",
        "\n",
        "# 2. 예측 수행\n",
        "print(\"\\n2. balanced 모델로 테스트 데이터 예측 중...\")\n",
        "y_pred_balanced = balanced_model.predict(X_test)\n",
        "print(\"예측 완료\")\n",
        "\n",
        "# 3. 평가 (혼동 행렬, 분류 리포트)\n",
        "print(\"\\n3. balanced 모델 평가 중...\")\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(f\"\\n혼동 행렬(Confusion Matrix) - balanced:\")\n",
        "cm_bal = confusion_matrix(y_test, y_pred_balanced)\n",
        "print(cm_bal)\n",
        "\n",
        "print(f\"\\n분류 리포트(Classification Report) - balanced:\")\n",
        "report_bal = classification_report(y_test, y_pred_balanced)\n",
        "print(report_bal)\n",
        "\n",
        "print(\"\\n=== 가중치 조정(balanced) 로지스틱 회귀 재학습 및 평가 완료 ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. LightGBM 모델 학습 및 평가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LightGBM 모델 학습 및 평가\n",
        "print(\"\\n=== LightGBM 모델 학습 및 평가 시작 ===\")\n",
        "\n",
        "# 1. LightGBM 모델 학습\n",
        "print(\"\\n1. LightGBM 모델 학습 중...\")\n",
        "\n",
        "# lightgbm 라이브러리에서 LGBMClassifier 임포트\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# LGBMClassifier 모델 생성 (is_unbalance=True로 불균형 데이터 처리)\n",
        "lgb_model = LGBMClassifier(random_state=42, is_unbalance=True, verbose=-1)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "print(\"LightGBM 모델 학습 완료\")\n",
        "\n",
        "# 2. 예측 및 평가\n",
        "print(\"\\n2. LightGBM 모델로 테스트 데이터 예측 중...\")\n",
        "y_pred_lgb = lgb_model.predict(X_test)\n",
        "print(\"예측 완료\")\n",
        "\n",
        "# 3. 평가 (혼동 행렬, 분류 리포트)\n",
        "print(\"\\n3. LightGBM 모델 평가 중...\")\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(f\"\\n혼동 행렬(Confusion Matrix) - LightGBM:\")\n",
        "cm_lgb = confusion_matrix(y_test, y_pred_lgb)\n",
        "print(cm_lgb)\n",
        "\n",
        "print(f\"\\n분류 리포트(Classification Report) - LightGBM:\")\n",
        "report_lgb = classification_report(y_test, y_pred_lgb)\n",
        "print(report_lgb)\n",
        "\n",
        "print(\"\\n=== LightGBM 모델 학습 및 평가 완료 ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 피처 중요도 분석 및 시각화\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 피처 중요도 분석\n",
        "print(\"\\n=== 피처 중요도 분석 시작 ===\")\n",
        "\n",
        "# 1. 피처 중요도 계산\n",
        "print(\"\\n1. 피처 중요도 계산 중...\")\n",
        "feature_importance = lgb_model.feature_importances_\n",
        "print(\"피처 중요도 계산 완료\")\n",
        "\n",
        "# 피처 이름과 중요도를 매핑\n",
        "feature_names = feature_columns\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance\n",
        "})\n",
        "\n",
        "# 중요도 순으로 정렬\n",
        "importance_df = importance_df.sort_values('importance', ascending=True)\n",
        "print(\"\\n피처 중요도 (낮은 순):\")\n",
        "print(importance_df)\n",
        "\n",
        "# 2. 피처 중요도 시각화\n",
        "print(\"\\n2. 피처 중요도 시각화 중...\")\n",
        "\n",
        "# matplotlib과 seaborn 임포트\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 한글 폰트 설정 (Windows 환경)\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 그래프 크기 설정\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# 가로 막대 그래프 생성\n",
        "plt.barh(importance_df['feature'], importance_df['importance'], color='skyblue', alpha=0.7)\n",
        "\n",
        "# 그래프 제목과 라벨 설정\n",
        "plt.title('LightGBM 모델 피처 중요도', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('중요도 점수', fontsize=12)\n",
        "plt.ylabel('피처', fontsize=12)\n",
        "\n",
        "# 격자 추가\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# 중요도 값 표시\n",
        "for i, v in enumerate(importance_df['importance']):\n",
        "    plt.text(v + 0.1, i, f'{v:.2f}', va='center', fontsize=10)\n",
        "\n",
        "# 레이아웃 조정\n",
        "plt.tight_layout()\n",
        "\n",
        "# 그래프 저장 및 표시\n",
        "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"피처 중요도 그래프 생성 완료 (feature_importance.png로 저장됨)\")\n",
        "\n",
        "# 3. 결과 해석\n",
        "print(\"\\n3. 피처 중요도 해석:\")\n",
        "print(\"=\" * 50)\n",
        "for idx, row in importance_df.iterrows():\n",
        "    print(f\"{row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "print(\"\\n=== 피처 중요도 분석 완료 ===\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
